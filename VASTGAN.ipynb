{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Conv2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "def crop_center(img, crop_size=None):\n",
    "    (y,x,_) = img.shape\n",
    "    xo, yo = (x//2, y//2)\n",
    "    crop_size = int(min(x,y)/2) if not crop_size else crop_size\n",
    "    result = img[yo-crop_size:yo+crop_size,xo-crop_size:xo+crop_size]\n",
    "    return result\n",
    "directory = './sample/'\n",
    "images = []\n",
    "for imagefile in os.listdir(directory):\n",
    "    image = Image.open(os.path.join(directory, imagefile), 'r')\n",
    "    img_array = np.asarray(image, 'float32')\n",
    "    images.append(crop_center(img_array))\n",
    "images = np.array(images, dtype=\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#f, axarr = plt.subplots(4, 4, figsize=(10,10))\n",
    "#for i in range(4):\n",
    "    #for j in range(4):\n",
    "        #plt.axes(axarr[i,j])\n",
    "        #plt.imshow(images[4*i+j])\n",
    "        #plt.xticks([])\n",
    "        #plt.yticks([])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_dim=100, output_dim=1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(4*64*64))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    # reshaped matrix should be 1/4 of output shape\n",
    "    model.add(Reshape(( 64, 64,4), input_shape=(4*64*64,)))\n",
    "    model.add(UpSampling2D(size=(2, 2), data_format='channels_last'))\n",
    "    model.add(Conv2D(64, (5, 5), border_mode='same', data_format='channels_last'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(UpSampling2D(size=(2, 2), data_format='channels_last'))\n",
    "    model.add(Conv2D(3, (5, 5), border_mode='same', data_format='channels_last'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (5, 5),\n",
    "                        border_mode='same',\n",
    "                        input_shape=(256, 256,3), data_format='channels_last'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_last'))\n",
    "    model.add(Conv2D(128, (5, 5), border_mode='same', data_format='channels_last'))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_last'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num)/width))\n",
    "    shape = generated_images.shape[2:]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[0, :, :]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate(BATCH_SIZE, nice=False, prefix=\"\"):\n",
    "    generator = generator_model()\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    generator.load_weights('generator.h5py')\n",
    "    if nice:\n",
    "        discriminator = discriminator_model()\n",
    "        discriminator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "        discriminator.load_weights('discriminator.h5py')\n",
    "        noise = np.zeros((BATCH_SIZE*20, 100))\n",
    "        for i in range(BATCH_SIZE*20):\n",
    "            noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "        generated_images = generator.predict(noise, verbose=1)\n",
    "        d_pret = discriminator.predict(generated_images, verbose=1)\n",
    "        index = np.arange(0, BATCH_SIZE*20)\n",
    "        index.resize((BATCH_SIZE*20, 1))\n",
    "        pre_with_index = list(np.append(d_pret, index, axis=1))\n",
    "        pre_with_index.sort(key=lambda x: x[0], reverse=True)\n",
    "        nice_images = np.zeros((BATCH_SIZE, 1) +\n",
    "                               (generated_images.shape[2:]), dtype=np.float32)\n",
    "        for i in range(int(BATCH_SIZE)):\n",
    "            idx = int(pre_with_index[i][1])\n",
    "            nice_images[i, 0, :, :] = generated_images[idx, 0, :, :]\n",
    "        image = combine_images(nice_images)\n",
    "    else:\n",
    "        noise = np.zeros((BATCH_SIZE, 100))\n",
    "        for i in range(BATCH_SIZE):\n",
    "            noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "        generated_images = generator.predict(noise, verbose=1)\n",
    "        image = combine_images(generated_images)\n",
    "    image = image*127.5+127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(prefix+\n",
    "        \"generated_image.png\")\n",
    "def example(prefix=\"\"):\n",
    "    generator = generator_model()\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    generator.load_weights('generator.h5py')\n",
    "    noise = np.zeros((BATCH_SIZE, 100))\n",
    "    for i in range(BATCH_SIZE):\n",
    "        noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "    image = generator.predict(noise, verbose=1)\n",
    "    print('generated image '+str(image.shape))\n",
    "    image = image*127.5+127.5\n",
    "    image = image[0,:,:,:]\n",
    "    Image.fromarray(image.astype(np.uint8)).save(prefix+\"generated_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "losses_graph = []\n",
    "def train(BATCH_SIZE,continue_save=True):\n",
    "    import numpy as np\n",
    "    import os\n",
    "    from PIL import Image\n",
    "    def crop_center(img):\n",
    "        (y,x,_) = img.shape\n",
    "        xo, yo = (x//2, y//2)\n",
    "        crop_size = int(min(x,y)/2)\n",
    "        result = img[yo-crop_size:yo+crop_size,xo-crop_size:xo+crop_size]\n",
    "        return result\n",
    "    directory = './small/'\n",
    "    images = []\n",
    "    for imagefile in os.listdir(directory):\n",
    "        image = Image.open(os.path.join(directory, imagefile), 'r')\n",
    "        img_array = np.asarray(image, 'float32')\n",
    "        images.append(crop_center(img_array))\n",
    "    images = np.array(images, dtype=\"float32\")\n",
    "    X_train = images\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    \n",
    "    generator = generator_model()\n",
    "    discriminator = discriminator_model()\n",
    "\n",
    "    discriminator_on_generator = \\\n",
    "        generator_containing_discriminator(generator, discriminator)\n",
    "    d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    generator.compile(loss='binary_crossentropy', optimizer=\"SGD\")\n",
    "    discriminator_on_generator.compile(\n",
    "        loss='binary_crossentropy', optimizer=g_optim)\n",
    "    discriminator.trainable = True\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
    "    noise = np.zeros((BATCH_SIZE, 100))\n",
    "    \n",
    "    \n",
    "    if continue_save and os.path.isfile('generator.h5py') and os.path.isfile('discriminator.h5py'):\n",
    "        generator.load_weights('generator.h5py')\n",
    "        discriminator.load_weights('discriminator.h5py')\n",
    "    for epoch in range(50):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "        for index in range(int(X_train.shape[0]/BATCH_SIZE)):\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            generated_images = generator.predict(noise, verbose=0)\n",
    "                \n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "            \n",
    "            d_loss = discriminator.train_on_batch(X, y)\n",
    "            print(\"batch %d d_loss : %f\" % (index, d_loss))\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, 100)\n",
    "            discriminator.trainable = False\n",
    "            \n",
    "            g_loss = discriminator_on_generator.train_on_batch(\n",
    "                noise, [1] * BATCH_SIZE)\n",
    "            discriminator.trainable = True\n",
    "            print(\"batch %d g_loss : %f\" % (index, g_loss))\n",
    "            if index % 5 == 0:\n",
    "                generator.save_weights('generator.h5py', True)\n",
    "                discriminator.save_weights('discriminator.h5py', True)\n",
    "            example(prefix=\"%d_\"%(epoch*int(X_train.shape[0]/BATCH_SIZE)+index))\n",
    "            print(\"weights saved for index %d\" % (epoch*int(X_train.shape[0]/BATCH_SIZE)+index))\n",
    "            losses_graph.append((d_loss, g_loss))\n",
    "    return losses_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rudolf/.local/lib/python3.5/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=100, units=1024)`\n",
      "  app.launch_new_instance()\n",
      "/home/rudolf/.local/lib/python3.5/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), data_format=\"channels_last\", padding=\"same\")`\n",
      "/home/rudolf/.local/lib/python3.5/site-packages/ipykernel/__main__.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(3, (5, 5), data_format=\"channels_last\", padding=\"same\")`\n",
      "/home/rudolf/.local/lib/python3.5/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), data_format=\"channels_last\", input_shape=(256, 256,..., padding=\"same\")`\n",
      "/home/rudolf/.local/lib/python3.5/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (5, 5), data_format=\"channels_last\", padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.665695\n",
      "batch 0 g_loss : 0.496203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rudolf/.local/lib/python3.5/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=100, units=1024)`\n",
      "  app.launch_new_instance()\n",
      "/home/rudolf/.local/lib/python3.5/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), data_format=\"channels_last\", padding=\"same\")`\n",
      "/home/rudolf/.local/lib/python3.5/site-packages/ipykernel/__main__.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(3, (5, 5), data_format=\"channels_last\", padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 0\n",
      "batch 1 d_loss : 0.580166\n",
      "batch 1 g_loss : 0.384631\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 1\n",
      "batch 2 d_loss : 0.536770\n",
      "batch 2 g_loss : 0.298484\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 2\n",
      "batch 3 d_loss : 0.524399\n",
      "batch 3 g_loss : 0.227753\n",
      "32/32 [==============================] - 14s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 3\n",
      "Epoch is 1\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.468935\n",
      "batch 0 g_loss : 0.190340\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 4\n",
      "batch 1 d_loss : 0.482383\n",
      "batch 1 g_loss : 0.166250\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 5\n",
      "batch 2 d_loss : 0.492619\n",
      "batch 2 g_loss : 0.151214\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 6\n",
      "batch 3 d_loss : 0.519679\n",
      "batch 3 g_loss : 0.139276\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 7\n",
      "Epoch is 2\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.472767\n",
      "batch 0 g_loss : 0.138390\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 8\n",
      "batch 1 d_loss : 0.473199\n",
      "batch 1 g_loss : 0.146387\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 9\n",
      "batch 2 d_loss : 0.480336\n",
      "batch 2 g_loss : 0.158657\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 10\n",
      "batch 3 d_loss : 0.500006\n",
      "batch 3 g_loss : 0.169361\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 11\n",
      "Epoch is 3\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.463614\n",
      "batch 0 g_loss : 0.191359\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 12\n",
      "batch 1 d_loss : 0.445537\n",
      "batch 1 g_loss : 0.221765\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 13\n",
      "batch 2 d_loss : 0.460094\n",
      "batch 2 g_loss : 0.251201\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 14\n",
      "batch 3 d_loss : 0.499292\n",
      "batch 3 g_loss : 0.274784\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 15\n",
      "Epoch is 4\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.466055\n",
      "batch 0 g_loss : 0.294556\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 16\n",
      "batch 1 d_loss : 0.439189\n",
      "batch 1 g_loss : 0.336906\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 17\n",
      "batch 2 d_loss : 0.458588\n",
      "batch 2 g_loss : 0.364247\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 18\n",
      "batch 3 d_loss : 0.521961\n",
      "batch 3 g_loss : 0.368609\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 19\n",
      "Epoch is 5\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.468648\n",
      "batch 0 g_loss : 0.390358\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 20\n",
      "batch 1 d_loss : 0.435181\n",
      "batch 1 g_loss : 0.408315\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 21\n",
      "batch 2 d_loss : 0.459571\n",
      "batch 2 g_loss : 0.437604\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 22\n",
      "batch 3 d_loss : 0.500896\n",
      "batch 3 g_loss : 0.429160\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 23\n",
      "Epoch is 6\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.425143\n",
      "batch 0 g_loss : 0.423079\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 24\n",
      "batch 1 d_loss : 0.368031\n",
      "batch 1 g_loss : 0.435403\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 25\n",
      "batch 2 d_loss : 0.408244\n",
      "batch 2 g_loss : 0.412287\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 26\n",
      "batch 3 d_loss : 0.403084\n",
      "batch 3 g_loss : 0.379663\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 27\n",
      "Epoch is 7\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.325850\n",
      "batch 0 g_loss : 0.336658\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 28\n",
      "batch 1 d_loss : 0.288986\n",
      "batch 1 g_loss : 0.288430\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 29\n",
      "batch 2 d_loss : 0.380228\n",
      "batch 2 g_loss : 0.211625\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 30\n",
      "batch 3 d_loss : 0.309978\n",
      "batch 3 g_loss : 0.149769\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 31\n",
      "Epoch is 8\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.229008\n",
      "batch 0 g_loss : 0.105319\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 32\n",
      "batch 1 d_loss : 0.207112\n",
      "batch 1 g_loss : 0.073640\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 33\n",
      "batch 2 d_loss : 0.299772\n",
      "batch 2 g_loss : 0.046394\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 34\n",
      "batch 3 d_loss : 0.212418\n",
      "batch 3 g_loss : 0.029043\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 35\n",
      "Epoch is 9\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.155389\n",
      "batch 0 g_loss : 0.019001\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 36\n",
      "batch 1 d_loss : 0.131871\n",
      "batch 1 g_loss : 0.014044\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 37\n",
      "batch 2 d_loss : 0.204416\n",
      "batch 2 g_loss : 0.009171\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 38\n",
      "batch 3 d_loss : 0.140340\n",
      "batch 3 g_loss : 0.006221\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 39\n",
      "Epoch is 10\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.107928\n",
      "batch 0 g_loss : 0.004683\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 40\n",
      "batch 1 d_loss : 0.085276\n",
      "batch 1 g_loss : 0.003895\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 41\n",
      "batch 2 d_loss : 0.140498\n",
      "batch 2 g_loss : 0.002828\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 42\n",
      "batch 3 d_loss : 0.093653\n",
      "batch 3 g_loss : 0.002285\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 43\n",
      "Epoch is 11\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.069487\n",
      "batch 0 g_loss : 0.001876\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 44\n",
      "batch 1 d_loss : 0.054251\n",
      "batch 1 g_loss : 0.001709\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 45\n",
      "batch 2 d_loss : 0.103987\n",
      "batch 2 g_loss : 0.001380\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 46\n",
      "batch 3 d_loss : 0.062542\n",
      "batch 3 g_loss : 0.001134\n",
      "32/32 [==============================] - 14s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 47\n",
      "Epoch is 12\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.042955\n",
      "batch 0 g_loss : 0.000981\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 48\n",
      "batch 1 d_loss : 0.034706\n",
      "batch 1 g_loss : 0.000948\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 49\n",
      "batch 2 d_loss : 0.080343\n",
      "batch 2 g_loss : 0.000765\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 50\n",
      "batch 3 d_loss : 0.043903\n",
      "batch 3 g_loss : 0.000682\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 51\n",
      "Epoch is 13\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.028566\n",
      "batch 0 g_loss : 0.000612\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 52\n",
      "batch 1 d_loss : 0.024290\n",
      "batch 1 g_loss : 0.000566\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 53\n",
      "batch 2 d_loss : 0.061961\n",
      "batch 2 g_loss : 0.000488\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 54\n",
      "batch 3 d_loss : 0.032431\n",
      "batch 3 g_loss : 0.000422\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 55\n",
      "Epoch is 14\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.020857\n",
      "batch 0 g_loss : 0.000373\n",
      "32/32 [==============================] - 16s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 56\n",
      "batch 1 d_loss : 0.018460\n",
      "batch 1 g_loss : 0.000365\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 57\n",
      "batch 2 d_loss : 0.047907\n",
      "batch 2 g_loss : 0.000324\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 58\n",
      "batch 3 d_loss : 0.025257\n",
      "batch 3 g_loss : 0.000295\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 59\n",
      "Epoch is 15\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.017419\n",
      "batch 0 g_loss : 0.000271\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 60\n",
      "batch 1 d_loss : 0.015071\n",
      "batch 1 g_loss : 0.000263\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 61\n",
      "batch 2 d_loss : 0.039314\n",
      "batch 2 g_loss : 0.000251\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 62\n",
      "batch 3 d_loss : 0.020205\n",
      "batch 3 g_loss : 0.000223\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 63\n",
      "Epoch is 16\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.014408\n",
      "batch 0 g_loss : 0.000209\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 64\n",
      "batch 1 d_loss : 0.012413\n",
      "batch 1 g_loss : 0.000204\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 65\n",
      "batch 2 d_loss : 0.033056\n",
      "batch 2 g_loss : 0.000198\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 66\n",
      "batch 3 d_loss : 0.016949\n",
      "batch 3 g_loss : 0.000177\n",
      "32/32 [==============================] - 19s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 67\n",
      "Epoch is 17\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.012536\n",
      "batch 0 g_loss : 0.000173\n",
      "32/32 [==============================] - 17s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 68\n",
      "batch 1 d_loss : 0.011028\n",
      "batch 1 g_loss : 0.000171\n",
      "32/32 [==============================] - 16s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 69\n",
      "batch 2 d_loss : 0.029484\n",
      "batch 2 g_loss : 0.000160\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 70\n",
      "batch 3 d_loss : 0.014839\n",
      "batch 3 g_loss : 0.000157\n",
      "32/32 [==============================] - 18s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 71\n",
      "Epoch is 18\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.010934\n",
      "batch 0 g_loss : 0.000154\n",
      "32/32 [==============================] - 18s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 72\n",
      "batch 1 d_loss : 0.009506\n",
      "batch 1 g_loss : 0.000157\n",
      "32/32 [==============================] - 17s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 73\n",
      "batch 2 d_loss : 0.027213\n",
      "batch 2 g_loss : 0.000149\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 74\n",
      "batch 3 d_loss : 0.012995\n",
      "batch 3 g_loss : 0.000150\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 75\n",
      "Epoch is 19\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.009566\n",
      "batch 0 g_loss : 0.000149\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 76\n",
      "batch 1 d_loss : 0.008389\n",
      "batch 1 g_loss : 0.000140\n",
      "32/32 [==============================] - 24s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 77\n",
      "batch 2 d_loss : 0.025258\n",
      "batch 2 g_loss : 0.000130\n",
      "32/32 [==============================] - 26s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 78\n",
      "batch 3 d_loss : 0.011944\n",
      "batch 3 g_loss : 0.000132\n",
      "32/32 [==============================] - 24s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 79\n",
      "Epoch is 20\n",
      "Number of batches 4\n",
      "batch 0 d_loss : 0.008769\n",
      "batch 0 g_loss : 0.000138\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 80\n",
      "batch 1 d_loss : 0.008078\n",
      "batch 1 g_loss : 0.000135\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 81\n",
      "batch 2 d_loss : 0.023874\n",
      "batch 2 g_loss : 0.000131\n",
      "32/32 [==============================] - 24s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 82\n",
      "batch 3 d_loss : 0.011022\n",
      "batch 3 g_loss : 0.000124\n",
      "32/32 [==============================] - 15s\n",
      "generated image (32, 256, 256, 3)\n",
      "weights saved for index 83\n",
      "Epoch is 21\n",
      "Number of batches 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a43f61427520>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlosses_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlosses_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c51cb5907c12>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(BATCH_SIZE, continue_save)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch %d d_loss : %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m    939\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[1;32m    940\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                                          class_weight=class_weight)\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     def test_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1619\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "losses_graph = train(BATCH_SIZE)\n",
    "losses_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4ba0a57dbabf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlosses_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'losses_graph' is not defined"
     ]
    }
   ],
   "source": [
    "losses_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rudolf/.local/lib/python3.5/site-packages/ipykernel/__main__.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=100, units=1024)`\n",
      "  app.launch_new_instance()\n",
      "/home/rudolf/.local/lib/python3.5/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), data_format=\"channels_last\", padding=\"same\")`\n",
      "/home/rudolf/.local/lib/python3.5/site-packages/ipykernel/__main__.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(3, (5, 5), data_format=\"channels_last\", padding=\"same\")`\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a66bf628c530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-04bdfb06358f>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(BATCH_SIZE, nice, prefix)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mnoise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m127.5\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m127.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1571\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1573\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1201\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import vgg16\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    assert K.ndim(x) == 3\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        features = K.batch_flatten(x)\n",
    "    else:\n",
    "        features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9ad56373a7e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_nrows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_ncols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_outputs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "img_nrows,img_ncols,f_outputs= 256,256,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_loss_and_grads(x):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((1, 3, img_nrows, img_ncols))\n",
    "    else:\n",
    "        x = x.reshape((1, img_nrows, img_ncols, 3))\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "class Evaluator(object):\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = Evaluator()\n",
    "\n",
    "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
    "# so as to minimize the neural style loss\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x = np.random.uniform(0, 255, (1, 3, img_nrows, img_ncols)) - 128.\n",
    "else:\n",
    "    x = np.random.uniform(0, 255, (1, img_nrows, img_ncols, 3)) - 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# util function to open, resize and format pictures into appropriate tensors\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg16.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, img_nrows, img_ncols))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((img_nrows, img_ncols, 3))\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "from scipy.misc import imsave\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    # save current generated image\n",
    "    img = deprocess_image(x.copy())\n",
    "    fname = result_prefix + '_at_iteration_%d.png' % i\n",
    "    imsave(fname, img)\n",
    "    end_time = time.time()\n",
    "    print('Image saved as', fname)\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
